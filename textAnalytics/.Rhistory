library(ggplot2)
str(mpg)
qplot(displ, hwy, data=mpg)
qplot(displ, hwy, data=mpg, color=hwy)
qplot(displ, hwy, data=mpg, color=drv)
qplot(displ, hwy, data=mpg, geom=c("point", "smooth"))
qplot(hwy, data=mpg, fill=drv)
qplot(displ, hwy, data=mpg, facets= .~rv)
qplot(displ, hwy, data=mpg, facets= .~drv)
qplot(hwy, data=mpg, facets=drv~.)
qplot(hwy, data=mpg, facets=drv~., binwidth=2)
library(caret)
install.packages("caret")
library(caret)
setwd("~/Documents/edX/analyticsEdge/textAnalytics")
trials = read.csv('../data/clinical_trial.csv', stringsAsFactors=FALSE)
#1.1
max(nchar(trials$abstract))
#1.2
nrow(subset(trials, nchar(abstract)==0))
#1.3
match(min(nchar(trials$title)),nchar(trials$title))
trials[match(min(nchar(trials$title)),nchar(trials$title))]
trials[1258]
trials$title[match(min(nchar(trials$title)),nchar(trials$title))]
library(tm)
library(SnowballC)
corpusTitle = Corpus(VectorSource(trials$title))
corpusAbstract = Corpus(VectorSource(trials$abstract))
corpusTitle = Corpus(VectorSource(trials$title))
corpusAbstract = Corpus(VectorSource(trials$abstract))
corpusTitle = tm_map(corpusTitle, tolower)
corpusAbstract = tm_map(corpusAbstract, tolower)
corpusTitle = tm_map(corpusTitle, PlainTextDocument)
corpusAbstract = tm_map(corpusAbstract, PlainTextDocument)
corpusTitle = tm_map(corpusTitle, removePunctuation)
corpusAbstract = tm_map(corpusAbstract, removePunctuation)
corpusTitle = tm_map(corpusTitle, removeWords, stopwords("English"))
corpusAbstract = tm_map(corpusAbstract, removeWords, stopwords("English"))
corpusTitle = tm_map(corpusTitle, stemDocument)
corpusAbstract = tm_map(corpusAbstract, stemDocument)
dtmTitle = DocumentTermMatrix(corpusTitle)
dtmAbstract = DocumentTermMatrix(corpusAbstract)
#create sparse matrices
sparseTitle = removeSparseTerms(dtmTitle, .95)
sparseAbstract = removeSparseTerms(dtmAbstract, .95)
dtmTitle = as.data.frame(as.matrix(sparseTitle))
dtmAbstract = as.data.frame(as.matrix(sparseAbstract))
length(stopwords("english"))
str(dtmTitle)
summary(dtmTitle)
str(dtmAbstract)
?colnums
?colnum
?colSums
colSums(dtmAbstract)
sort(colSums(dtmAbstract))
colnames(dtmTitle) = paste0("T", colnames(dtmTitle))
colnames(dtmAbstract) = paste0("A", colnames(dtmAbstract))
dtm = cbind(dtmTitle, dtmAbstract)
dtm$trial = trials$trial
dtm = cbind(dtmTitle, dtmAbstract)
dtm$trial = trials$trial
#2.3 most common word in abstract
sort(colSums(dtmAbstract))
##3.1
colnames(dtmTitle) = paste0("T", colnames(dtmTitle))
colnames(dtmAbstract) = paste0("A", colnames(dtmAbstract))
library(caTools)
set.seed(144)
split = sample.split(dtm, SplitRatio = 0.7)
train = subset(dtm, split == TRUE)
test = subset(dtm, split == FALSE)
table(train$trial)
726/(726+574)
library(rpart)
library(rpart.plot)
?rpart
trialCART = rpart(trial ~ ., data = train, method = "class")
prp(trialCART)
table(trialCART)
table(trialCART$trial)
trialCART
predict(trialCART)
table(predict(trialCART))
table(predict(trialCART, type="class"))
786/(786+514)
table(predict(trialCART))
predTrain = predict(trialCART)
View(predTrain)
sum(predTrain[,2])
nrow(predTrain)
574/1300
predTrain = predict(trialCart)[,2]
summary(predTrain)
predTrain = predict(trialCart)[,2]
predTrain = predict(trialCART)[,2]
summary(predTrain)
predTrain = predict(trialCART)[,2]
summary(predTrain)
pred = predict(trialCART, newdata = test, type="class")
table(test$trial, pred)
(270+168)/(270+47+75+168)
270/(270+75)
168/(168+47)
pred = predict(trialCART, newdata = test)
table(test$trial, pred)
table(test$trial, pred)
pred = predict(trialCART, newdata = test)
View(pred)
table(test$trial, pred)
pred = predict(trialCART, newdata = test, type="class")
table(test$trial, pred)
pred = predict(trialCART, newdata = test, type="class")
table(test$trial, pred>0.5)
pred = predict(trialCART, newdata = test)
table(test$trial, pred>0.5)
trialCART = rpart(trial ~ ., data = train, method = "class")
prp(trialCART)
predTrain = predict(trialCART)[,2]
summary(predTrain)
ibrary(caTools)
set.seed(144)
split = sample.split(dtm, SplitRatio = 0.7)
train = subset(dtm, split == TRUE)
test = subset(dtm, split == FALSE)
##3.4
library(rpart)
library(rpart.plot)
trialCART = rpart(trial ~ ., data = train, method = "class")
predTrain = predict(trialCART)[,2]
summary(predTrain
)
trialCART = rpart(trial ~ ., data = train, method = "class")
predTrain = predict(trialCART)[,2]
summary(predTrain)
pred = predict(trialCART, newdata = test)
pred = predict(trialCART, newdata = test)
table(test$trial, pred)
pred = predict(trialCART, newdata = test)
table(test$trial, pred)
pred = predict(trialCART, newdata = test, type = "class")
table(test$trial, pred)
(270+168)/(270+168+47+75)
pam = read.csv('..data/emails.csv', stringsAsFactors=FALSE)
get.wd()
getwd()
spam = read.csv('..data/emails.csv', stringsAsFactors=FALSE)
getwd()
list.files('..data')
list.files('../data')
spam = read.csv('../data/emails.csv', stringsAsFactors=FALSE)
spam = read.csv('../data/emails.csv', stringsAsFactors=FALSE)
summary(spam)
sum(spam$spam)
emails = read.csv('../data/emails.csv', stringsAsFactors=FALSE)
max(nchar(emails$text))
match(min(nchar(emails$text)), nchar(emails$text))
library(tm)
library(SnowballC)
corpus = Corpus(VectorSource(emails$text))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("English"))
corpus = tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
summary(dtm)
summary(dtm)
str(dtm)
length(stopwords("english"))
library(tm)
library(SnowballC)
corpus = Corpus(VectorSource(emails$text))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("English"))
corpus = tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
dtm
dtm = removeSparseTerms(dtm, .95)
dtm
dtm = as.data.frame(as.matrix(dtm))
emailsSparse = as.data.frame(as.matrix(dtm))
sort(colSums(emailsSparse))
emailsSparse$spam = emails$spam
sum(emails$Sparse)
sum(emailsSparse$spam)
sort(colSums(emails))
library(SnowballC)
corpus = Corpus(VectorSource(emails$text))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("English"))
corpus = tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
dtm = removeSparseTerms(dtm, .95)
spdtm = as.data.frame(as.matrix(dtm))
##2.3
sort(colSums(spdtm))
##2.4
spdtm$spam = emails$spam
corpus = Corpus(VectorSource(emails$text))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("English"))
corpus = tm_map(corpus, stemDocument)
dtm = DocumentTermMatrix(corpus)
spdtm = removeSparseTerms(dtm, .95)
emailsSparse = as.data.frame(as.matrix(spdtm))
##2.3
sort(colSums(emailsSparse))
##2.4
emailsSparse$spam = emails$spam
str(emailsSparse)
hamSparse = subset(emailsSparse, spam=0)
sort(colSums(hamSparse))
hamSparse = subset(emailsSparse, spam==0)
sort(colSums(hamSparse))
colSums(hamSparse) > 1000
sum(colSums(hamSparse) > 1000)
hamSparse1000 = subset(hamSparse, colSums(hamSparse) > 1000)
emailsSparse1000 = subset(emailsSparse, colSums(emailsSparse) > 1000)
